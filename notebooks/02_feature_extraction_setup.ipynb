{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37659d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febbc23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'src' directory to the Python path to import modules\n",
    "# Notebooks are in 'notebooks/' written modules are in 'src/'\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import data loader and feature extraction functions from modules\n",
    "from src.data_loader import load_androids_corpus\n",
    "\n",
    "from src.mshds_extractor import extract_mshds_features\n",
    "from src.opensmile_extractor import extract_opensmile_features\n",
    "from src.foundation_model_extractor import extract_wav2vec2_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eed0b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Androids Corpus...\n",
      "Successfully loaded 112 Read task and 116 Interview task fold assignments.\n",
      "\n",
      "Processing Reading Task from: E:\\Dissertation_Data\\Androids-Corpus\\Reading-Task\\audio\n",
      "Warning: Could not parse filename '59_PF36_x.wav' in Reading-Task\n",
      "Processed 111 files from Reading-Task.\n",
      "\n",
      "Processing Interview Task clips from: E:\\Dissertation_Data\\Androids-Corpus\\Interview-Task\\audio_clip\n",
      "Warning: Could not parse interview session folder name: '59_PF36_x'\n",
      "Warning: Could not parse interview session folder name: '60_PF56_x'\n",
      "Processed 866 clip files from Interview-Task (audio_clip).\n",
      "\n",
      "--- Data Loading Complete ---\n"
     ]
    }
   ],
   "source": [
    "# Define base path to data\n",
    "BASE_CORPUS_PATH = 'E:/Dissertation_Data/Androids-Corpus'\n",
    "\n",
    "# Call function to load the data\n",
    "print(\"Loading Androids Corpus...\")\n",
    "reading_df, interview_df = load_androids_corpus(BASE_CORPUS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45a57887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Reading Task Data ---\n",
      "Shape: (111, 10)\n",
      "  unique_participant_id original_id_nn    label  gender  age  education  \\\n",
      "0                  01_C             01  Control  Female   56          1   \n",
      "1                  02_C             02  Control    Male   57          2   \n",
      "2                  03_C             03  Control  Female   30          3   \n",
      "3                  04_C             04  Control  Female   57          3   \n",
      "4                  05_C             05  Control  Female   41          3   \n",
      "\n",
      "                                            filepath       filename task_type  \\\n",
      "0  E:/Dissertation_Data/Androids-Corpus\\Reading-T...  01_CF56_1.wav   Reading   \n",
      "1  E:/Dissertation_Data/Androids-Corpus\\Reading-T...  02_CM57_2.wav   Reading   \n",
      "2  E:/Dissertation_Data/Androids-Corpus\\Reading-T...  03_CF30_3.wav   Reading   \n",
      "3  E:/Dissertation_Data/Androids-Corpus\\Reading-T...  04_CF57_3.wav   Reading   \n",
      "4  E:/Dissertation_Data/Androids-Corpus\\Reading-T...  05_CF41_3.wav   Reading   \n",
      "\n",
      "   fold  \n",
      "0     1  \n",
      "1     1  \n",
      "2     5  \n",
      "3     5  \n",
      "4     2  \n"
     ]
    }
   ],
   "source": [
    "# Header of reading task DataFrame\n",
    "print(\"\\n--- Reading Task Data ---\")\n",
    "if not reading_df.empty:\n",
    "    print(f\"Shape: {reading_df.shape}\")\n",
    "    print(reading_df.head())\n",
    "else:\n",
    "    print(\"Reading DataFrame is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9a8eb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Interview Task Data ---\n",
      "Shape: (866, 11)\n",
      "  unique_participant_id original_id_nn    label  gender  age  education  \\\n",
      "0                  01_C             01  Control  Female   56          1   \n",
      "1                  01_C             01  Control  Female   56          1   \n",
      "2                  01_C             01  Control  Female   56          1   \n",
      "3                  01_C             01  Control  Female   56          1   \n",
      "4                  01_C             01  Control  Female   56          1   \n",
      "\n",
      "                                            filepath          filename  \\\n",
      "0  E:/Dissertation_Data/Androids-Corpus\\Interview...   01_CF56_1_1.wav   \n",
      "1  E:/Dissertation_Data/Androids-Corpus\\Interview...  01_CF56_1_10.wav   \n",
      "2  E:/Dissertation_Data/Androids-Corpus\\Interview...   01_CF56_1_2.wav   \n",
      "3  E:/Dissertation_Data/Androids-Corpus\\Interview...   01_CF56_1_3.wav   \n",
      "4  E:/Dissertation_Data/Androids-Corpus\\Interview...   01_CF56_1_4.wav   \n",
      "\n",
      "  original_session_filename       task_type  fold  \n",
      "0                 01_CF56_1  Interview_Clip     1  \n",
      "1                 01_CF56_1  Interview_Clip     1  \n",
      "2                 01_CF56_1  Interview_Clip     1  \n",
      "3                 01_CF56_1  Interview_Clip     1  \n",
      "4                 01_CF56_1  Interview_Clip     1  \n"
     ]
    }
   ],
   "source": [
    "# Header of interview task DataFrame\n",
    "print(\"\\n--- Interview Task Data ---\")\n",
    "if not interview_df.empty:\n",
    "    print(f\"Shape: {interview_df.shape}\")\n",
    "    print(interview_df.head())\n",
    "else:\n",
    "    print(\"Interview DataFrame is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc79803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a small test DataFrame with 5 files:\n",
      "['01_CF56_1.wav', '02_CM57_2.wav', '03_CF30_3.wav', '04_CF57_3.wav', '05_CF41_3.wav']\n"
     ]
    }
   ],
   "source": [
    "# Create small subset for testing\n",
    "small_reading_df = reading_df.head(5).copy() # .copy() to avoid SettingWithCopyWarning\n",
    "print(\"Created a small test DataFrame with 5 files:\")\n",
    "print(small_reading_df['filename'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dd6117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting MSHDS features for the small test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c7b0066fa04fe7b89c6604f8474cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting MSHDS Features:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete!\n"
     ]
    }
   ],
   "source": [
    "# Extract MSHDS features for the small test set\n",
    "print(\"\\nExtracting MSHDS features for the small test set...\")\n",
    "# Progress bar of feature extraction\n",
    "test_features_df = extract_mshds_features(small_reading_df, verbose=True)\n",
    "print(\"Extraction complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb8e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the output feature DataFrame: (5, 26)\n",
      "\n",
      "Number of missing values per feature:\n",
      "filename                    0\n",
      "Speaking_Rate               0\n",
      "Articulation_Rate           0\n",
      "Phonation_Ratio             0\n",
      "Pause_Rate                  0\n",
      "Mean_Pause_Duration         0\n",
      "mean_F0                     0\n",
      "stdev_F0_Semitone           0\n",
      "mean_dB                     0\n",
      "range_ratio_dB              0\n",
      "HNR_dB                      0\n",
      "Spectral_Slope              0\n",
      "Spectral_Tilt               0\n",
      "Cepstral_Peak_Prominence    0\n",
      "mean_F1_Loc                 0\n",
      "std_F1_Loc                  0\n",
      "mean_B1_Loc                 0\n",
      "std_B1_Loc                  0\n",
      "mean_F2_Loc                 0\n",
      "std_F2_Loc                  0\n",
      "mean_B2_Loc                 0\n",
      "std_B2_Loc                  0\n",
      "Spectral_Gravity            0\n",
      "Spectral_Std_Dev            0\n",
      "Spectral_Skewness           0\n",
      "Spectral_Kurtosis           0\n",
      "dtype: int64\n",
      "\n",
      "Head of the feature DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Speaking_Rate</th>\n",
       "      <th>Articulation_Rate</th>\n",
       "      <th>Phonation_Ratio</th>\n",
       "      <th>Pause_Rate</th>\n",
       "      <th>Mean_Pause_Duration</th>\n",
       "      <th>mean_F0</th>\n",
       "      <th>stdev_F0_Semitone</th>\n",
       "      <th>mean_dB</th>\n",
       "      <th>range_ratio_dB</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_B1_Loc</th>\n",
       "      <th>std_B1_Loc</th>\n",
       "      <th>mean_F2_Loc</th>\n",
       "      <th>std_F2_Loc</th>\n",
       "      <th>mean_B2_Loc</th>\n",
       "      <th>std_B2_Loc</th>\n",
       "      <th>Spectral_Gravity</th>\n",
       "      <th>Spectral_Std_Dev</th>\n",
       "      <th>Spectral_Skewness</th>\n",
       "      <th>Spectral_Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01_CF56_1.wav</td>\n",
       "      <td>3.221843</td>\n",
       "      <td>4.078672</td>\n",
       "      <td>0.789924</td>\n",
       "      <td>0.342143</td>\n",
       "      <td>0.614000</td>\n",
       "      <td>135.486474</td>\n",
       "      <td>3.477464</td>\n",
       "      <td>63.951329</td>\n",
       "      <td>2.155580</td>\n",
       "      <td>...</td>\n",
       "      <td>255.168680</td>\n",
       "      <td>286.616317</td>\n",
       "      <td>1633.716904</td>\n",
       "      <td>488.536986</td>\n",
       "      <td>594.657072</td>\n",
       "      <td>716.782932</td>\n",
       "      <td>355.206497</td>\n",
       "      <td>337.788948</td>\n",
       "      <td>5.964434</td>\n",
       "      <td>70.606271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02_CM57_2.wav</td>\n",
       "      <td>3.402797</td>\n",
       "      <td>4.119856</td>\n",
       "      <td>0.825951</td>\n",
       "      <td>0.253400</td>\n",
       "      <td>0.686857</td>\n",
       "      <td>95.854561</td>\n",
       "      <td>3.352660</td>\n",
       "      <td>65.361857</td>\n",
       "      <td>2.016766</td>\n",
       "      <td>...</td>\n",
       "      <td>242.927026</td>\n",
       "      <td>253.067458</td>\n",
       "      <td>1614.980076</td>\n",
       "      <td>448.984263</td>\n",
       "      <td>492.187366</td>\n",
       "      <td>439.490258</td>\n",
       "      <td>363.889176</td>\n",
       "      <td>393.584860</td>\n",
       "      <td>6.691924</td>\n",
       "      <td>121.864942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03_CF30_3.wav</td>\n",
       "      <td>4.388955</td>\n",
       "      <td>5.117387</td>\n",
       "      <td>0.857656</td>\n",
       "      <td>0.177931</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>201.023993</td>\n",
       "      <td>2.082710</td>\n",
       "      <td>65.586717</td>\n",
       "      <td>2.360642</td>\n",
       "      <td>...</td>\n",
       "      <td>260.924023</td>\n",
       "      <td>288.588630</td>\n",
       "      <td>1704.686010</td>\n",
       "      <td>484.051893</td>\n",
       "      <td>662.627477</td>\n",
       "      <td>905.501959</td>\n",
       "      <td>460.918213</td>\n",
       "      <td>421.403730</td>\n",
       "      <td>5.051323</td>\n",
       "      <td>55.662546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04_CF57_3.wav</td>\n",
       "      <td>4.384482</td>\n",
       "      <td>5.207409</td>\n",
       "      <td>0.841970</td>\n",
       "      <td>0.259297</td>\n",
       "      <td>0.609455</td>\n",
       "      <td>173.834010</td>\n",
       "      <td>2.489167</td>\n",
       "      <td>68.230038</td>\n",
       "      <td>3.053060</td>\n",
       "      <td>...</td>\n",
       "      <td>147.257021</td>\n",
       "      <td>133.237838</td>\n",
       "      <td>1553.763156</td>\n",
       "      <td>398.784342</td>\n",
       "      <td>371.078992</td>\n",
       "      <td>485.221797</td>\n",
       "      <td>576.765021</td>\n",
       "      <td>477.447754</td>\n",
       "      <td>4.396186</td>\n",
       "      <td>39.211027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05_CF41_3.wav</td>\n",
       "      <td>4.676964</td>\n",
       "      <td>5.254031</td>\n",
       "      <td>0.890167</td>\n",
       "      <td>0.201160</td>\n",
       "      <td>0.546000</td>\n",
       "      <td>197.308449</td>\n",
       "      <td>3.552315</td>\n",
       "      <td>69.091985</td>\n",
       "      <td>3.231895</td>\n",
       "      <td>...</td>\n",
       "      <td>179.709255</td>\n",
       "      <td>253.194893</td>\n",
       "      <td>1557.978158</td>\n",
       "      <td>543.890373</td>\n",
       "      <td>571.127516</td>\n",
       "      <td>632.109680</td>\n",
       "      <td>457.281058</td>\n",
       "      <td>344.699651</td>\n",
       "      <td>6.319892</td>\n",
       "      <td>83.131251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename  Speaking_Rate  Articulation_Rate  Phonation_Ratio  \\\n",
       "0  01_CF56_1.wav       3.221843           4.078672         0.789924   \n",
       "1  02_CM57_2.wav       3.402797           4.119856         0.825951   \n",
       "2  03_CF30_3.wav       4.388955           5.117387         0.857656   \n",
       "3  04_CF57_3.wav       4.384482           5.207409         0.841970   \n",
       "4  05_CF41_3.wav       4.676964           5.254031         0.890167   \n",
       "\n",
       "   Pause_Rate  Mean_Pause_Duration     mean_F0  stdev_F0_Semitone    mean_dB  \\\n",
       "0    0.342143             0.614000  135.486474           3.477464  63.951329   \n",
       "1    0.253400             0.686857   95.854561           3.352660  65.361857   \n",
       "2    0.177931             0.800000  201.023993           2.082710  65.586717   \n",
       "3    0.259297             0.609455  173.834010           2.489167  68.230038   \n",
       "4    0.201160             0.546000  197.308449           3.552315  69.091985   \n",
       "\n",
       "   range_ratio_dB  ...  mean_B1_Loc  std_B1_Loc  mean_F2_Loc  std_F2_Loc  \\\n",
       "0        2.155580  ...   255.168680  286.616317  1633.716904  488.536986   \n",
       "1        2.016766  ...   242.927026  253.067458  1614.980076  448.984263   \n",
       "2        2.360642  ...   260.924023  288.588630  1704.686010  484.051893   \n",
       "3        3.053060  ...   147.257021  133.237838  1553.763156  398.784342   \n",
       "4        3.231895  ...   179.709255  253.194893  1557.978158  543.890373   \n",
       "\n",
       "   mean_B2_Loc  std_B2_Loc  Spectral_Gravity  Spectral_Std_Dev  \\\n",
       "0   594.657072  716.782932        355.206497        337.788948   \n",
       "1   492.187366  439.490258        363.889176        393.584860   \n",
       "2   662.627477  905.501959        460.918213        421.403730   \n",
       "3   371.078992  485.221797        576.765021        477.447754   \n",
       "4   571.127516  632.109680        457.281058        344.699651   \n",
       "\n",
       "   Spectral_Skewness  Spectral_Kurtosis  \n",
       "0           5.964434          70.606271  \n",
       "1           6.691924         121.864942  \n",
       "2           5.051323          55.662546  \n",
       "3           4.396186          39.211027  \n",
       "4           6.319892          83.131251  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check shape: Should have 5 rows and 26 columns (25 features + 1 filename)\n",
    "print(f\"\\nShape of the output feature DataFrame: {test_features_df.shape}\")\n",
    "\n",
    "# Check for missing values. Should be all zeros.\n",
    "# Non-zero counts, means some files had errors during extraction.\n",
    "print(\"\\nNumber of missing values per feature:\")\n",
    "print(test_features_df.isnull().sum())\n",
    "\n",
    "# Display the first few rows to visually inspect the features\n",
    "print(\"\\nHead of the feature DataFrame:\")\n",
    "display(test_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2528710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting MSHDS features for the FULL Reading Task set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0d21438c9f4e5d88e0d654bce8c37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting MSHDS Features:   0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full feature extraction and merge complete! ---\n",
      "Shape of final DataFrame: (111, 35)\n",
      "\n",
      "Saving extracted features to: ../data/features_mshds_reading_task.csv\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Extracting features for full reading task set\n",
    "print(\"\\nExtracting MSHDS features for the FULL Reading Task set...\")\n",
    "mshds_reading_features_df = extract_mshds_features(reading_df)\n",
    "\n",
    "# Merge the features extracted from the reading task audio back with the original metadata from reading_df\n",
    "full_reading_data = pd.merge(reading_df, mshds_reading_features_df, on='filename', how='left')\n",
    "\n",
    "print(\"\\n--- Full feature extraction and merge complete! ---\")\n",
    "print(f\"Shape of final DataFrame: {full_reading_data.shape}\")\n",
    "\n",
    "# Save the final DataFrame to a CSV for future use\n",
    "output_path = '../data/features_mshds_reading_task.csv'\n",
    "print(f\"\\nSaving extracted features to: {output_path}\")\n",
    "full_reading_data.to_csv(output_path, index=False)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5a078e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the OpenSMILE executable\n",
    "OPENSMILE_EXE_PATH = 'E:/tools/opensmile-3.0.2/bin/SMILExtract.exe'\n",
    "\n",
    "# Path to the OpenSMILE config file\n",
    "CONFIG_FILE_PATH = os.path.join(BASE_CORPUS_PATH, 'Androids.conf')\n",
    "\n",
    "# Path for saving the processed features\n",
    "OPENSMILE_OUTPUT_PATH = '../data/Processed_Features/features_opensmile_reading_task.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2dd5634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting OpenSMILE features for the Reading Task...\n",
      "Using temporary directory for OpenSMILE outputs: C:\\Users\\ayush\\AppData\\Local\\Temp\\tmpfi2tohtn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbe444d31df421a88d9dca47dd988b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting OpenSMILE Features:   0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving OpenSMILE features to: ../data/Processed_Features/features_opensmile_reading_task.csv\n",
      "OpenSMILE features saved.\n",
      "\n",
      "--- All feature extraction checks complete. ---\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(OPENSMILE_OUTPUT_PATH):\n",
    "    print(f\"\\nExtracting OpenSMILE features for the Reading Task...\")\n",
    "    if not os.path.exists(OPENSMILE_EXE_PATH):\n",
    "        print(f\"FATAL ERROR: OpenSMILE executable not found at '{OPENSMILE_EXE_PATH}'.\")\n",
    "    else:\n",
    "        opensmile_features_df = extract_opensmile_features(\n",
    "            input_df=reading_df,\n",
    "            opensmile_exe_path=OPENSMILE_EXE_PATH,\n",
    "            config_file_path=CONFIG_FILE_PATH\n",
    "        )\n",
    "        if not opensmile_features_df.empty:\n",
    "            full_reading_data_opensmile = pd.merge(reading_df, opensmile_features_df, on='filename', how='left')\n",
    "            print(f\"Saving OpenSMILE features to: {OPENSMILE_OUTPUT_PATH}\")\n",
    "            full_reading_data_opensmile.to_csv(OPENSMILE_OUTPUT_PATH, index=False)\n",
    "            print(\"OpenSMILE features saved.\")\n",
    "else:\n",
    "    print(f\"\\nOpenSMILE features already exist at: {OPENSMILE_OUTPUT_PATH}. Loading from file.\")\n",
    "    full_reading_data_opensmile = pd.read_csv(OPENSMILE_OUTPUT_PATH)\n",
    "    \n",
    "print(\"\\n--- All feature extraction checks complete. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48d5ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model to use and the output path\n",
    "MODEL_NAME = \"facebook/wav2vec2-base-960h\"\n",
    "EMBEDDINGS_OUTPUT_PATH = '../data/Processed_Features/features_wav2vec2_reading_task.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5857879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting embeddings from facebook/wav2vec2-base-960h for the Reading Task...\n",
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f2cdd559684203ae7feb6b33e8912d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayush\\miniconda3\\envs\\msc_speech_framework\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ayush\\.cache\\huggingface\\hub\\models--facebook--wav2vec2-base-960h. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8b1d96bb4e4779864f84ab06265401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c84ca7142f44f38ef03641e232c72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ad1deab5ea4994852ae996ff46bd38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dddbc4c4d084915a57791b3d4233e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465c82e5486d4907bf8adf20ab39ea83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f10832e7614532933eee9394d60ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting wav2vec2-base-960h Embeddings:   0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Wav2Vec2 embeddings to: ../data/Processed_Features/features_wav2vec2_reading_task.csv\n",
      "Embeddings saved.\n",
      "\n",
      "--- All feature extraction tasks are complete. ---\n"
     ]
    }
   ],
   "source": [
    "# Check if features already exist to save time\n",
    "if not os.path.exists(EMBEDDINGS_OUTPUT_PATH):\n",
    "    print(f\"\\nExtracting embeddings from {MODEL_NAME} for the Reading Task...\")\n",
    "    wav2vec2_features_df = extract_wav2vec2_embeddings(reading_df)\n",
    "    \n",
    "    if not wav2vec2_features_df.empty:\n",
    "        # Merge the features back with the original metadata\n",
    "        full_reading_data_wav2vec2 = pd.merge(reading_df, wav2vec2_features_df, on='filename', how='left')\n",
    "        \n",
    "        print(f\"Saving Wav2Vec2 embeddings to: {EMBEDDINGS_OUTPUT_PATH}\")\n",
    "        full_reading_data_wav2vec2.to_csv(EMBEDDINGS_OUTPUT_PATH, index=False)\n",
    "        print(\"Embeddings saved.\")\n",
    "else:\n",
    "    print(f\"\\nWav2Vec2 embeddings already exist at: {EMBEDDINGS_OUTPUT_PATH}. Loading from file.\")\n",
    "    full_reading_data_wav2vec2 = pd.read_csv(EMBEDDINGS_OUTPUT_PATH)\n",
    "\n",
    "print(\"\\n--- All feature extraction tasks are complete. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d77274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_final_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
